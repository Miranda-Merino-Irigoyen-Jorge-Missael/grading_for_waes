"""
test_vertex.py -- Script de diagnÃ³stico para Vertex AI
Corre: python test_vertex.py
"""
import time
import logging
import vertexai
from vertexai.generative_models import GenerativeModel, Part
from src.config import Config

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("test_vertex")

# â”€â”€ Inicializar Vertex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vertexai.init(project=Config.PROJECT_ID, location=Config.LOCATION)

# â”€â”€ TEST 1: Texto puro (sin PDFs) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_1_texto_puro():
    logger.info("=" * 60)
    logger.info("TEST 1: Texto puro - DiagnÃ³stico bÃ¡sico de conectividad")
    logger.info("=" * 60)
    model = GenerativeModel("gemini-2.0-flash-001")
    prompt = "Responde en una sola oraciÃ³n: Â¿CuÃ¡l es la capital de MÃ©xico?"
    
    t0 = time.time()
    logger.info("â³ Enviando peticiÃ³n...")
    chunks = []
    try:
        response_stream = model.generate_content(prompt, stream=True)
        for i, chunk in enumerate(response_stream):
            if i == 0:
                logger.info(f"âœ… Primer token en {time.time()-t0:.1f}s")
            chunks.append(chunk.text if hasattr(chunk, 'text') and chunk.text else "")
        full_text = "".join(chunks)
        logger.info(f"âœ… Ã‰XITO. Respuesta en {time.time()-t0:.1f}s: {full_text[:100]}")
        return True
    except Exception as e:
        logger.error(f"âŒ FALLO: {e}")
        return False


# â”€â”€ TEST 2: Un PDF pequeÃ±o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_2_un_pdf(pdf_path: str):
    logger.info("=" * 60)
    logger.info(f"TEST 2: Un PDF - {pdf_path}")
    logger.info("=" * 60)
    model = GenerativeModel("gemini-2.0-flash-001")
    
    with open(pdf_path, "rb") as f:
        pdf_bytes = f.read()
    logger.info(f"   PDF cargado: {len(pdf_bytes)/1024:.1f} KB")

    prompt_parts = [
        Part.from_data(data=pdf_bytes, mime_type="application/pdf"),
        "Resume en 3 lÃ­neas el contenido de este documento."
    ]
    
    t0 = time.time()
    logger.info("â³ Enviando peticiÃ³n con PDF...")
    chunks = []
    try:
        response_stream = model.generate_content(prompt_parts, stream=True)
        for i, chunk in enumerate(response_stream):
            if i == 0:
                logger.info(f"âœ… Primer token en {time.time()-t0:.1f}s")
            chunks.append(chunk.text if hasattr(chunk, 'text') and chunk.text else "")
        full_text = "".join(chunks)
        logger.info(f"âœ… Ã‰XITO. Completado en {time.time()-t0:.1f}s, {len(full_text)} chars.")
        return True
    except Exception as e:
        logger.error(f"âŒ FALLO: {e}")
        return False


# â”€â”€ TEST 3: Varios PDFs (simula el proceso real) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_3_multiples_pdfs(pdf_paths: list):
    logger.info("=" * 60)
    logger.info(f"TEST 3: {len(pdf_paths)} PDFs - Equivalente al proceso real")
    logger.info("=" * 60)
    model = GenerativeModel("gemini-2.0-flash-001")
    
    parts = []
    total_kb = 0
    for label, path in pdf_paths:
        with open(path, "rb") as f:
            data = f.read()
        total_kb += len(data)/1024
        parts.append(Part.from_data(data=data, mime_type="application/pdf"))
        logger.info(f"   {label}: {len(data)/1024:.1f} KB")
    
    logger.info(f"   Total payload: {total_kb:.1f} KB")
    parts.append("Resume en 5 lÃ­neas el contenido de TODOS estos documentos.")
    
    t0 = time.time()
    logger.info("â³ Enviando peticiÃ³n con mÃºltiples PDFs...")
    chunks = []
    try:
        response_stream = model.generate_content(parts, stream=True)
        for i, chunk in enumerate(response_stream):
            if i == 0:
                logger.info(f"âœ… Primer token en {time.time()-t0:.1f}s")
            elif i % 5 == 0:
                logger.info(f"   ðŸ“ {i} chunks recibidos en {time.time()-t0:.1f}s...")
            chunks.append(chunk.text if hasattr(chunk, 'text') and chunk.text else "")
        full_text = "".join(chunks)
        logger.info(f"âœ… Ã‰XITO. Completado en {time.time()-t0:.1f}s, {len(full_text)} chars.")
        return True
    except Exception as e:
        logger.error(f"âŒ FALLO: {type(e).__name__}: {e}")
        return False


# â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import glob, os, sys
    
    logger.info("ðŸ”¬ Iniciando diagnÃ³stico de Vertex AI...")
    logger.info(f"   Proyecto: {Config.PROJECT_ID}")
    logger.info(f"   RegiÃ³n: {Config.LOCATION}")

    # TEST 1: Sin PDFs
    ok1 = test_1_texto_puro()

    if not ok1:
        logger.error("âŒ Fallo en Test 1 (texto puro). Problema crÃ­tico de conectividad con Vertex.")
        logger.error("   -> Verifica credenciales y acceso a internet.")
        sys.exit(1)

    # Buscar PDFs en output para tests 2 y 3
    pdfs = glob.glob(r"output\grading_results\**\*.pdf", recursive=True)
    if not pdfs:
        # Intenta en temp si hay algo
        logger.warning("No hay PDFs locales de prueba. Solo se ejecutÃ³ Test 1.")
        sys.exit(0)

    # TEST 2: Un PDF
    test_2_un_pdf(pdfs[0])

    # TEST 3: MÃºltiples PDFs si hay suficientes
    if len(pdfs) >= 2:
        test_3_multiples_pdfs([(os.path.basename(p), p) for p in pdfs[:4]])
    
    logger.info("âœ… DiagnÃ³stico finalizado.")
